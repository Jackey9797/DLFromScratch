{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import torch \n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "import torchkeras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(func):\n",
    "    def func_wrapper(*args,**kwargs):\n",
    "        from time import time\n",
    "        time_start = time()\n",
    "        result = func(*args,**kwargs)\n",
    "        time_end = time()\n",
    "        time_spend = time_end - time_start\n",
    "        print('{0} Training cost time {1} s\\n'.format(args[0].__class__.__name__, round(time_spend, 2)))\n",
    "        return result\n",
    "    return func_wrapper\n",
    "\n",
    "def show_fig():\n",
    "    plt.ion()\n",
    "    def draw(x, *kwargs): \n",
    "        print(kwargs)\n",
    "        for y, z in kwargs.items(): \n",
    "            plt.plot(x, y, label=y)\n",
    "        # plt.plot(np.arange(i) + 1, train_loss_list, label=\"Train Loss\")\n",
    "        # plt.plot(np.arange(i) + 1, valid_loss_list, label=\"Valid Loss\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    return draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_L2_loss(model): \n",
    "    loss = torch.zeros(1) \n",
    "    for i in model.parameters(): \n",
    "        for j in i: \n",
    "            if len(j.shape) > 1: \n",
    "                loss += torch.sum(j ** 2) \n",
    "    return loss\n",
    "    \n",
    "\n",
    "def train_step(model, x, y): \n",
    "    model.train() \n",
    "    model.optimizer.zero_grad()\n",
    "\n",
    "    pred = model(x) \n",
    "\n",
    "    # print(pred.shape, y.shape)\n",
    "\n",
    "    loss = model.loss_func(pred, y) + 0.00015 * get_L2_loss(model) \n",
    "    metric = model.metric_func(pred, y)\n",
    "\n",
    "    loss.backward() \n",
    "\n",
    "\n",
    "    # p_grad = [p for p in model.parameters() if p.requires_grad] + [p for q in model.W_hh.values() for p in q.parameters() if p.requires_grad] + [p  for q in model.W_hx.values() for p in q.parameters() if p.requires_grad]\n",
    "    # # print([i.grad) for i in p_grad] + []) \n",
    "    # norm = torch.sqrt(sum(torch.sum(p.grad ** 2) for p in p_grad))\n",
    "    \n",
    "    \n",
    "    # if norm > 1: \n",
    "    #     for p in p_grad: \n",
    "    #         p.grad[:] *= 1 / norm  \n",
    "\n",
    "    model.optimizer.step() #? loss 和 optimize各自扮演的角色\n",
    "    return loss.item(), metric.item()\n",
    "\n",
    "def valid_step(model, x, y):\n",
    "    model.eval() #? 实现\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        pred = model(x)\n",
    "        loss = model.loss_func(pred, y)\n",
    "        metric = model.metric_func(pred, y)\n",
    "    return loss.item(), metric.item()\n",
    "\n",
    "@timer\n",
    "def train_model(model, epoch, train_dl, valid_dl, log_step_freq, plt_curve=False): \n",
    "    metric_name = model.metric_name \n",
    "    df_history = pd.DataFrame(columns = [\"epoch\", \"loss\", metric_name, \"val_loss\",\"val_\" + metric_name])\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    print(\"Start Training...\\n\")\n",
    "\n",
    "    for i in range(1, epoch + 1): \n",
    "        #*-----------------------train loop-----------------------------------------\n",
    "        cnt = 0\n",
    "        loss_sum = 0 \n",
    "        metric_sum = 0\n",
    "\n",
    "        step = 1\n",
    "        for step, (x, y) in enumerate(train_dl, 1): \n",
    "            loss, metric = train_step(model, x, y) #! \n",
    "            \n",
    "            loss_sum += loss \n",
    "            metric_sum += metric #!\n",
    "            cnt += len(y) ##TODO BUG\n",
    "\n",
    "            if step % log_step_freq == 0: \n",
    "                print((\"[step = %d] loss: %.3f, \" + metric_name + \": %.3f\") % \n",
    "                        (step, loss_sum / step, metric_sum / step))  #step这里有大问题\n",
    "        \n",
    "        #*-----------------------valid loop-----------------------------------------\n",
    "        val_loss_sum = 0\n",
    "        val_metric_sum = 0\n",
    "        val_step = 1 \n",
    "        val_cnt = 0\n",
    "\n",
    "        for val_step, (x, y) in enumerate(valid_dl, 1): \n",
    "            val_loss, val_metric = valid_step(model, x, y) \n",
    "            val_loss_sum += val_loss \n",
    "            val_metric_sum += val_metric \n",
    "            val_cnt += len(y)\n",
    "        # print(loss_sum)\n",
    "        info = (i, loss_sum / step, metric_sum / step, \n",
    "                val_loss_sum / val_step, val_metric_sum / val_step) \n",
    "        df_history.loc[epoch - 1] = info \n",
    "\n",
    "        # 打印epoch级别日志\n",
    "        # print(cnt)\n",
    "        train_loss_list.append(loss_sum / cnt)\n",
    "        valid_loss_list.append(val_loss_sum / val_cnt)\n",
    "        if plt_curve : \n",
    "            plt.plot(np.arange(i) + 1, train_loss_list, label=\"Train Loss\")\n",
    "            plt.plot(np.arange(i) + 1, valid_loss_list, label=\"Valid Loss\")\n",
    "            plt.legend()\n",
    "            myfig = plt.gcf()\n",
    "            myfig.savefig(\"Train.png\")\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "        else : print((\"EPOCH = %d, loss = %.3f,\"+ metric_name + \\\n",
    "            \" = %.3f, val_loss = %.3f, \" + \"val_\" + metric_name + \" = %.3f\")\n",
    "            %info, \"\\n\")\n",
    "\n",
    "    \n",
    "    print(\"Training Finished!\\n\")\n",
    "    return df_history, train_loss_list, valid_loss_list\n",
    "\n",
    "#* 把整个pdf上的代码用MLP跑通，后续再在上面改"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9dee909b94f9b71f1735c26369abf02849623765c9fac88e4d4cba156fc12504"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
